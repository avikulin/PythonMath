{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"sentences.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import re as re\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(input_file_path):\n",
    "    raise FileNotFoundError(\"Input file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sentences = list()\n",
    "list_of_token_frequencies = list()\n",
    "tokens_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file_path,\"r\") as input_file:\n",
    "    counter = 0\n",
    "    for sentence in input_file:\n",
    "        input_tokens_list = re.split(\"[^a-zA-Z]\", sentence)\n",
    "        \n",
    "        token_frequency_dict = dict()\n",
    "        \n",
    "        for token in input_tokens_list:\n",
    "            if (token is not None) and (len(token)>0):\n",
    "                token = token.lower()\n",
    "                if token_frequency_dict.get(token) is None:\n",
    "                    token_frequency_dict[token] = 1\n",
    "                else:\n",
    "                    token_frequency_dict[token] += 1\n",
    "                \n",
    "                if (tokens_dict.get(token) is None):\n",
    "                    tokens_dict[token] = counter\n",
    "                    counter += 1\n",
    "        list_of_sentences.append(sentence)\n",
    "        list_of_token_frequencies.append(token_frequency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 254)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_matrix = np.zeros((len(list_of_sentences),len(tokens_dict)), dtype=int)\n",
    "word_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence_number, sentence_tokens_dict in enumerate(list_of_token_frequencies):\n",
    "    for tocken_word in sentence_tokens_dict.keys():\n",
    "        word_number = tokens_dict[tocken_word]\n",
    "        word_matrix[sentence_number][word_number] = sentence_tokens_dict[tocken_word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In comparison to dogs, cats have not undergone major changes during the domestication process.\n",
      "\n",
      "{'comparison': 1, 'undergone': 1, 'process': 1, 'major': 1, 'to': 1, 'cats': 1, 'have': 1, 'in': 1, 'not': 1, 'during': 1, 'the': 1, 'changes': 1, 'dogs': 1, 'domestication': 1}\n",
      "('In-', 0)\n",
      "('comparison -', 1)\n",
      "('to - ', 2)\n",
      "('dogs - ', 3)\n",
      "('cats - ', 4)\n",
      "('have - ', 5)\n",
      "('not - ', 6)\n",
      "('undergone - ', 7)\n",
      "('major - ', 8)\n",
      "('changes - ', 9)\n",
      "('during - ', 10)\n",
      "('the -', 11)\n",
      "('domestication - ', 12)\n",
      "('process - ', 13)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(list_of_sentences[0])\n",
    "print(list_of_token_frequencies[0])\n",
    "print(\"In-\", tokens_dict[\"in\"])\n",
    "print(\"comparison -\", tokens_dict[\"comparison\"])\n",
    "print(\"to - \", tokens_dict[\"to\"])\n",
    "print(\"dogs - \", tokens_dict[\"dogs\"])\n",
    "print(\"cats - \", tokens_dict[\"cats\"])\n",
    "print(\"have - \", tokens_dict[\"have\"])\n",
    "print(\"not - \", tokens_dict[\"not\"])\n",
    "print(\"undergone - \", tokens_dict[\"undergone\"])\n",
    "print(\"major - \", tokens_dict[\"major\"])\n",
    "print(\"changes - \", tokens_dict[\"changes\"])\n",
    "print(\"during - \", tokens_dict[\"during\"])\n",
    "print(\"the -\", tokens_dict[\"the\"])\n",
    "print(\"domestication - \", tokens_dict[\"domestication\"])\n",
    "print(\"process - \", tokens_dict[\"process\"])\n",
    "print(word_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = dict()\n",
    "for row_number, word_vector in enumerate(word_matrix):\n",
    "    distances[distance.cosine(word_vector, word_matrix[0])] = row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission-1.txt\", \"w\") as res_file:\n",
    "    res_str = \"\"\n",
    "    for key in sorted(distances.keys())[1:3]:\n",
    "        res_str += str(distances[key]) + \" \";\n",
    "    res_str = res_str[:-1]\n",
    "    res_file.write(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
